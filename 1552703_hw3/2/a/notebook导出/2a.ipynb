{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.optimize import leastsq\n",
    "import datetime\n",
    "import calendar\n",
    "\n",
    "def input():\n",
    "\n",
    "    data = pd.read_csv('trade_new.csv')\n",
    "    data = data.drop(['Unnamed: 0'], axis=1).fillna(-1)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def features_type1_p1_l1_w(col_name, data, new_col_sign):\n",
    "\n",
    "    # group by column_name\n",
    "    ## whole period\n",
    "    ### column_count_w\n",
    "    column_count = data[col_name].value_counts()\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(column_count.loc[row[col_name]])\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[new_col_sign+'_count_w'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "    ### column_amount_w\n",
    "    column_amount = data.groupby([col_name]).sum()\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(column_amount.loc[row[col_name]]['amt'])\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[new_col_sign+'_amount_w'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "    ### column_d_count_w\n",
    "    column_d_count = data.groupby([col_name,'day']).size()\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(column_d_count.loc[row[col_name]].count())\n",
    "    \n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[new_col_sign+'_d_count_w'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "def features_type1_p1_l1_m(col_name, data, new_col_sign):\n",
    "\n",
    "    ## monthly\n",
    "    ### column_count_m\n",
    "    column_count = data.groupby([col_name,'month']).size()\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(column_count.loc[row[col_name]].loc[row['month']])\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[new_col_sign+'_count_m'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "    ### column_amount_m\n",
    "    column_amount = data.groupby([col_name,'month']).sum()\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(column_amount.loc[row[col_name]].loc[row['month']]['amt'])\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[new_col_sign+'_amount_m'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "    ### column_d_count_m\n",
    "    column_d_count = data.groupby([col_name,'month','day']).size()\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(column_d_count.loc[row[col_name]].loc[row['month']].count())\n",
    "    \n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[new_col_sign+'_d_count_m'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "def features_type1_p1_l2_w(col_name1, col_name2, data, new_col_sign):\n",
    "\n",
    "    # group by column_name\n",
    "    ## whole period\n",
    "    ### column_count_w\n",
    "    column_count = data.groupby([col_name1, col_name2]).size()\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(column_count.loc[row[col_name1]].loc[row[col_name2]])\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[new_col_sign+'_count_w'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "    ### column_amount_w\n",
    "    column_amount = data.groupby([col_name1, col_name2]).sum()\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(column_amount.loc[row[col_name1]].loc[row[col_name2]]['amt'])\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[new_col_sign+'_amount_w'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "    ### column_d_count_w\n",
    "    column_d_count = data.groupby([col_name1, col_name2,'day']).size()\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(column_d_count.loc[row[col_name1]].loc[row[col_name2]].count())\n",
    "    \n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[new_col_sign+'_d_count_w'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "def features_type1_p1_l2_m(col_name1, col_name2, data, new_col_sign):\n",
    "\n",
    "    ## monthly\n",
    "    ### column_count_m\n",
    "    column_count = data.groupby([col_name1, col_name2,'month']).size()\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(column_count.loc[row[col_name1]].loc[row[col_name2]].loc[row['month']])\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[new_col_sign+'_count_m'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "    ### column_amount_m\n",
    "    column_amount = data.groupby([col_name1, col_name2,'month']).sum()\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(column_amount.loc[row[col_name1]].loc[row[col_name2]].loc[row['month']]['amt'])\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[new_col_sign+'_amount_m'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "    ### column_d_count_m\n",
    "    column_d_count = data.groupby([col_name1, col_name2,'month','day']).size()\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(column_d_count.loc[row[col_name1]].loc[row[col_name2]].loc[row['month']].count())\n",
    "    \n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[new_col_sign+'_d_count_m'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "def features_type1_p2_w(col_name, u_count_col_name, data, new_col_sign, u_count_col_sign):\n",
    "\n",
    "    # whole\n",
    "    column_u_count = data.groupby([col_name, u_count_col_name]).size()\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(column_u_count.loc[row[col_name]].count())\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[new_col_sign+'_u_count_'+u_count_col_sign+'_w'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "def features_type1_p2_m(col_name, u_count_col_name, data, new_col_sign, u_count_col_sign):\n",
    "\n",
    "    # monthly\n",
    "    column_u_count = data.groupby([col_name, 'month', u_count_col_name]).size()\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(column_u_count.loc[row[col_name]].loc[row['month']].count())\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[new_col_sign+'_u_count_'+u_count_col_sign+'_m'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "def features_type2_p1(col_name, data):\n",
    "\n",
    "    grouped = data[col_name].groupby(data['month'])\n",
    "\n",
    "    # mean\n",
    "    mean = grouped.mean()\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(mean.loc[row['month']])\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[col_name+'_mean'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "    # std\n",
    "    std = grouped.std()\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(std.loc[row['month']])\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[col_name+'_std'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "    # max\n",
    "    max_ = grouped.max()\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(max_.loc[row['month']])\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[col_name+'_max'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "    # median\n",
    "    median = grouped.median()\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(median.loc[row['month']])\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[col_name+'_median'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "    return data\n",
    "\n",
    "def features_type2_p2(col_name1, col_name2, data, signal):\n",
    "    \n",
    "    # day\n",
    "    grouped_day = data.groupby([data[col_name1], data[col_name2], data['day']]).size()\n",
    "    grouped_bndno = data.groupby([data[col_name1], data[col_name2]]).size()\n",
    "    grouped_day = pd.Series(data=1, index=grouped_day.index)\n",
    "    grouped_bndno = pd.Series(data=1, index=grouped_bndno.index)\n",
    "\n",
    "    new_group = []\n",
    "    for index, row in data.drop_duplicates([col_name1, col_name2]).iterrows():\n",
    "        new_group.append([row[col_name1], row[col_name2], grouped_day.loc[row[col_name1]].loc[row[col_name2]].count()])\n",
    "    new_data = pd.DataFrame(data=new_group, columns=[col_name1,col_name2, 'day_count'])\n",
    "    new_data = new_data.groupby([new_data[col_name1]])\n",
    "\n",
    "    ## mean\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(new_data.mean().loc[row[col_name1]]['day_count'])\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[col_name2+'_'+col_name1+'_days_mean'+signal])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "\n",
    "    ## std\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(new_data.std().loc[row[col_name1]]['day_count'])\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[col_name2+'_'+col_name1+'_days_std'+signal])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "    ## max\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(new_data.max().loc[row[col_name1]]['day_count'])\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[col_name2+'_'+col_name1+'_days_max'+signal])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "    ## median\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(new_data.median().loc[row[col_name1]]['day_count'])\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[col_name2+'_'+col_name1+'_days_median'+signal])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "    \n",
    "    # time\n",
    "    grouped_time = data.groupby([data[col_name1], data[col_name2]]).size()\n",
    "    ## mean\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(grouped_time.loc[row[col_name1]].mean())\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[col_name2+'_'+col_name1+'_times_mean'+signal])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "    ## std\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(grouped_time.loc[row[col_name1]].std())\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[col_name2+'_'+col_name1+'_times_std'+signal])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "    ## max\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(grouped_time.loc[row[col_name1]].max())\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[col_name2+'_'+col_name1+'_times_max'+signal])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "    ## median\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(grouped_time.loc[row[col_name1]].median())\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[col_name2+'_'+col_name1+'_times_median'+signal])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "    # amount\n",
    "    grouped_amount = data['amt'].groupby([data[col_name1], data[col_name2]]).sum()\n",
    "    ## mean\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(grouped_amount.loc[row[col_name1]].mean())\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[col_name2+'_'+col_name1+'_amount_mean'+signal])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "    ## std\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(grouped_amount.loc[row[col_name1]].std())\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[col_name2+'_'+col_name1+'_amount_std'+signal])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "    ## max\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(grouped_amount.loc[row[col_name1]].max())\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[col_name2+'_'+col_name1+'_amount_max'+signal])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "    ## median\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(grouped_amount.loc[row[col_name1]].median())\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[col_name2+'_'+col_name1+'_amount_median'+signal])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "def func(p,x):\n",
    "    k,b=p\n",
    "    return k*x+b\n",
    "\n",
    "def error(p,x,y):\n",
    "    return func(p,x)-y\n",
    "    \n",
    "def features_type4_p1_l1(col_name, data, signal):\n",
    "\n",
    "    grouped = data.groupby(data[col_name])\n",
    "\n",
    "    for feature in [signal+'_count_m', signal+'_amount_m', signal+'_d_count_m']:\n",
    "        trend_dic = {}\n",
    "        error_dic = {}\n",
    "\n",
    "        for name, group in grouped:\n",
    "\n",
    "            key = name\n",
    "            Y = []\n",
    "\n",
    "            for month in range(2, 8):\n",
    "                if group[group['month']==month].size > 0:\n",
    "                    Y.append(group[group['month']==month].iloc[0][feature])\n",
    "                else:\n",
    "                    Y.append(0)\n",
    "\n",
    "            # trend\n",
    "            X = np.array([1,2,3,4,5,6])\n",
    "            Y = np.array(Y)\n",
    "            p0=[1,0]\n",
    "            Para=leastsq(error,p0,args=(X,Y))\n",
    "            k,b=Para[0]\n",
    "\n",
    "            trend_dic[key] = k\n",
    "\n",
    "            # error\n",
    "            error_ = 0\n",
    "            for i in range(0, 5):\n",
    "                error_ += abs(Y[5]-Y[i])\n",
    "            error_dic[key] = error_/5\n",
    "\n",
    "        \n",
    "        new_col = []\n",
    "        for index, row in data.iterrows():\n",
    "            new_col.append(trend_dic[row[col_name]])\n",
    "\n",
    "        new_col = np.array(new_col).transpose()\n",
    "        new_col = pd.DataFrame(data=new_col, columns=[feature+'_trend'])\n",
    "\n",
    "        data = pd.concat([data, new_col], axis=1)\n",
    "\n",
    "        new_col = []\n",
    "        for index, row in data.iterrows():\n",
    "            new_col.append(error_dic[row[col_name]])\n",
    "\n",
    "        new_col = np.array(new_col).transpose()\n",
    "        new_col = pd.DataFrame(data=new_col, columns=[feature+'_error'])\n",
    "\n",
    "        data = pd.concat([data, new_col], axis=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "def features_type4_p1_l2(col_name1, col_name2, data, signal):\n",
    "\n",
    "    grouped = data.groupby([col_name1,col_name2])\n",
    "\n",
    "    for feature in [signal+'_count_m', signal+'_amount_m', signal+'_d_count_m']:\n",
    "        trend_dic = {}\n",
    "        error_dic = {}\n",
    "\n",
    "        for name, group in grouped:\n",
    "\n",
    "            key = name\n",
    "            Y = []\n",
    "\n",
    "            for month in range(2, 8):\n",
    "                if group[group['month']==month].size > 0:\n",
    "                    Y.append(group[group['month']==month].iloc[0][feature])\n",
    "                else:\n",
    "                    Y.append(0)\n",
    "\n",
    "            # trend\n",
    "            X = np.array([1,2,3,4,5,6])\n",
    "            Y = np.array(Y)\n",
    "            p0=[1,0]\n",
    "\n",
    "            Para=leastsq(error,p0,args=(X,Y))\n",
    "            k,b=Para[0]\n",
    "\n",
    "            trend_dic[key] = k\n",
    "\n",
    "            # error\n",
    "            error_ = 0\n",
    "            for i in range(0, 5):\n",
    "                error_ += abs(Y[5]-Y[i])\n",
    "            error_dic[key] = error_/5\n",
    "\n",
    "        \n",
    "        new_col = []\n",
    "        for index, row in data.iterrows():\n",
    "            new_col.append(trend_dic[(row[col_name1], row[col_name2])])\n",
    "\n",
    "        new_col = np.array(new_col).transpose()\n",
    "        new_col = pd.DataFrame(data=new_col, columns=[feature+'_trend'])\n",
    "\n",
    "        data = pd.concat([data, new_col], axis=1)\n",
    "\n",
    "        new_col = []\n",
    "        for index, row in data.iterrows():\n",
    "            new_col.append(error_dic[(row[col_name1], row[col_name2])])\n",
    "\n",
    "        new_col = np.array(new_col).transpose()\n",
    "        new_col = pd.DataFrame(data=new_col, columns=[feature+'_error'])\n",
    "\n",
    "        data = pd.concat([data, new_col], axis=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "def features_type4_p1_l3(col_name, u_count_col_name, data, new_col_sign, u_count_col_sign):\n",
    "\n",
    "    grouped = data.groupby([col_name,u_count_col_name])\n",
    "\n",
    "    trend_dic = {}\n",
    "    error_dic = {}\n",
    "\n",
    "    for name, group in grouped:\n",
    "\n",
    "        key = name\n",
    "        Y = []\n",
    "\n",
    "        for month in range(2, 8):\n",
    "            if group[group['month']==month].size > 0:\n",
    "                Y.append(group[group['month']==month].iloc[0][new_col_sign+'_u_count_'+u_count_col_sign+'_m'])\n",
    "            else:\n",
    "                Y.append(0)\n",
    "\n",
    "        # trend\n",
    "        X = np.array([1,2,3,4,5,6])\n",
    "        Y = np.array(Y)\n",
    "        p0=[1,0]\n",
    "\n",
    "        Para=leastsq(error,p0,args=(X,Y))\n",
    "        k,b=Para[0]\n",
    "\n",
    "        trend_dic[key] = k\n",
    "\n",
    "        # error\n",
    "        error_ = 0\n",
    "        for i in range(0, 5):\n",
    "            error_ += abs(Y[5]-Y[i])\n",
    "        error_dic[key] = error_/5\n",
    "\n",
    "        \n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(trend_dic[(row[col_name], row[u_count_col_name])])\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[new_col_sign+'_u_count_'+u_count_col_sign+'_m'+'_trend'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(error_dic[(row[col_name], row[u_count_col_name])])\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[new_col_sign+'_u_count_'+u_count_col_sign+'_m'+'_error'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "def features_type4_p2_t1(col_name, data):\n",
    "\n",
    "    # buyer\n",
    "    once = data.drop_duplicates(subset=[col_name, 'vipno'],keep='first')\n",
    "    much = data.drop_duplicates(subset=[col_name, 'vipno'],keep=False)  \n",
    "    much = once.append(much).drop_duplicates(subset=[col_name, 'vipno'],keep=False)  \n",
    "\n",
    "    count = much.drop_duplicates(subset=[col_name, 'vipno'],keep='first')\n",
    "    count = count['vipno'].groupby(count[col_name]).count()\n",
    "    whole = once['vipno'].groupby(data[col_name]).count()\n",
    "\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        if row[col_name] in count.index:\n",
    "            new_col.append(count.loc[row[col_name]])\n",
    "        else:\n",
    "            new_col.append(0)\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[col_name+'_much_count'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        if row[col_name] in count.index:\n",
    "            new_col.append(count.loc[row[col_name]]/whole.loc[row[col_name]])\n",
    "        else:\n",
    "            new_col.append(0)\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[col_name+'_much_count_ratio'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "\n",
    "    # day\n",
    "    once = data.drop_duplicates(subset=[col_name, 'vipno', 'day'],keep='first')\n",
    "    much = data.drop_duplicates(subset=[col_name, 'vipno', 'day'],keep=False)  \n",
    "    much = once.append(much).drop_duplicates(subset=[col_name, 'vipno', 'day'],keep=False)  \n",
    "\n",
    "    count = much['vipno'].groupby(much[col_name]).count()\n",
    "    whole = data['vipno'].groupby(data[col_name]).count()\n",
    "\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        if row[col_name] in count.index:\n",
    "            new_col.append(count.loc[row[col_name]])\n",
    "        else:\n",
    "            new_col.append(0)\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[col_name+'_much_day'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        if row[col_name] in count.index:\n",
    "            new_col.append(count.loc[row[col_name]]/whole.loc[row[col_name]])\n",
    "        else:\n",
    "            new_col.append(0)\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[col_name+'_much_day_ratio'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "def features_type4_p2_t2(col_name, data):\n",
    "\n",
    "    # count\n",
    "    once = data.drop_duplicates(subset=['vipno', col_name],keep='first')\n",
    "    much = data.drop_duplicates(subset=['vipno', col_name],keep=False)  \n",
    "    much = once.append(much).drop_duplicates(subset=['vipno', col_name],keep=False)  \n",
    "\n",
    "    count = much.drop_duplicates(subset=['vipno', col_name],keep='first')\n",
    "    count = count[col_name].groupby(count['vipno']).count()\n",
    "    whole = once[col_name].groupby(data['vipno']).count()\n",
    "\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        if row['vipno'] in count.index:\n",
    "            new_col.append(count.loc[row['vipno']])\n",
    "        else:\n",
    "            new_col.append(0)\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=['U_'+col_name+'_much_count'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        if row['vipno'] in count.index:\n",
    "            new_col.append(count.loc[row['vipno']]/whole.loc[row['vipno']])\n",
    "        else:\n",
    "            new_col.append(0)\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=['U_'+col_name+'_much_count_ratio'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "\n",
    "    # day\n",
    "    once = data.drop_duplicates(subset=['vipno', col_name, 'day'],keep='first')\n",
    "    much = data.drop_duplicates(subset=['vipno', col_name, 'day'],keep=False)  \n",
    "    much = once.append(much).drop_duplicates(subset=['vipno', col_name, 'day'],keep=False)  \n",
    "\n",
    "    count = much[col_name].groupby(much['vipno']).count()\n",
    "    whole = data[col_name].groupby(data['vipno']).count()\n",
    "\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        if row['vipno'] in count.index:\n",
    "            new_col.append(count.loc[row['vipno']])\n",
    "        else:\n",
    "            new_col.append(0)\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=['U_'+col_name+'_much_day'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        if row['vipno'] in count.index:\n",
    "            new_col.append(count.loc[row['vipno']]/whole.loc[row['vipno']])\n",
    "        else:\n",
    "            new_col.append(0)\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=['U_'+col_name+'_much_day_ratio'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "def features_type4_p3(col_name1, col_name2, data):\n",
    "\n",
    "    # once\n",
    "    once = data.drop_duplicates(subset=[col_name1, col_name2],keep='first')\n",
    "    part = 1\n",
    "    whole = once[col_name2].groupby(once[col_name1]).count()\n",
    "\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        new_col.append(part/whole.loc[row[col_name1]])\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[col_name1+'_'+col_name2+'_share_u'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "    # much\n",
    "    much = data\n",
    "    part = much['uid'].groupby([much[col_name1], much[col_name2]]).count()\n",
    "    whole = much[col_name2].groupby(data[col_name1]).count()\n",
    "\n",
    "    new_col = []\n",
    "    for index, row in data.iterrows():\n",
    "        if row[col_name2] in part.loc[row[col_name1]].index:\n",
    "            new_col.append(part.loc[row[col_name1]].loc[row[col_name2]]/whole.loc[row[col_name1]])\n",
    "        else:\n",
    "            new_col.append(0)\n",
    "\n",
    "    new_col = np.array(new_col).transpose()\n",
    "    new_col = pd.DataFrame(data=new_col, columns=[col_name1+'_'+col_name2+'_share_n'])\n",
    "\n",
    "    data = pd.concat([data, new_col], axis=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "def features_type4_p4(col_name1, col_name2, data):\n",
    "\n",
    "    # C\n",
    "    count_1 = data['uid'].groupby([data[col_name1], data[col_name2]]).count()\n",
    "    count_2 = data['vipno'].groupby([data[col_name1], data[col_name2]]).count()\n",
    "\n",
    "    # N\n",
    "    whole = data['uid'].groupby([data['vipno'], data[col_name2]]).count()\n",
    "\n",
    "    new_col_1 = []\n",
    "    new_col_2 = []\n",
    "    for index, row in data.iterrows():\n",
    "        \n",
    "        c = []\n",
    "        n = []\n",
    "        for col_name2_v in whole.loc[row['vipno']].index:\n",
    "            #print col_name1, col_name2, col_name2_v,count_1.loc[row[col_name1]]\n",
    "            if col_name2_v in count_1.loc[row[col_name1]].index:\n",
    "                c.append(count_1.loc[row[col_name1]].loc[col_name2_v] / count_1.loc[row[col_name1]].sum())\n",
    "            else:  \n",
    "                c.append(0)\n",
    "\n",
    "            n.append(whole.loc[row['vipno']].loc[col_name2_v])\n",
    "        \n",
    "        cn = []\n",
    "        for i in range(0, len(c)):\n",
    "            cn.append(c[i]*n[i])\n",
    "\n",
    "        new_col_1.append(np.mean(cn))\n",
    "        new_col_2.append(np.max(cn))\n",
    "\n",
    "    new_col_1 = np.array(new_col_1).transpose()\n",
    "    new_col_1 = pd.DataFrame(data=new_col_1, columns=[col_name1+'_'+col_name2+'_share_avg'])\n",
    "\n",
    "    data = pd.concat([data, new_col_1], axis=1)\n",
    "\n",
    "    new_col_2 = np.array(new_col_2).transpose()\n",
    "    new_col_2 = pd.DataFrame(data=new_col_2, columns=[col_name1+'_'+col_name2+'_share_max'])\n",
    "\n",
    "    data = pd.concat([data, new_col_2], axis=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "def type1(data):\n",
    "\n",
    "    day = []\n",
    "    for index, row in data.iterrows():\n",
    "        day.append(row['sldatime'][5:10])\n",
    "    day = np.array(day).transpose()\n",
    "    day = pd.DataFrame(data=day, columns=['day'])\n",
    "    data = pd.concat([data, day], axis=1)\n",
    "\n",
    "    month = []\n",
    "    for index, row in data.iterrows():\n",
    "        month.append(row['sldatime'][5:7])\n",
    "    month = np.array(month).transpose()\n",
    "    month = pd.DataFrame(data=month, columns=['month'])\n",
    "    data = pd.concat([data, month], axis=1)\n",
    "\n",
    "    # p1\n",
    "    # group by user\n",
    "    data = features_type1_p1_l1_w('vipno', data, 'U')\n",
    "    data = features_type1_p1_l1_m('vipno', data, 'U')\n",
    "    # group by brand\n",
    "    data = features_type1_p1_l1_w('bndno', data, 'B')\n",
    "    data = features_type1_p1_l1_m('bndno', data, 'B')\n",
    "    # group by category\n",
    "    data = features_type1_p1_l1_w('dptno', data, 'C')\n",
    "    data = features_type1_p1_l1_m('dptno', data, 'C')\n",
    "    # group by item\n",
    "    data = features_type1_p1_l1_w('pluno', data, 'I')\n",
    "    data = features_type1_p1_l1_m('pluno', data, 'I')\n",
    "    # user and brand\n",
    "    data = features_type1_p1_l2_w('vipno', 'bndno', data, 'UB')\n",
    "    data = features_type1_p1_l2_m('vipno', 'bndno', data, 'UB')\n",
    "    # user and category\n",
    "    data = features_type1_p1_l2_w('vipno', 'dptno', data, 'UC')\n",
    "    data = features_type1_p1_l2_m('vipno', 'dptno', data, 'UC')\n",
    "    # user and item \n",
    "    data = features_type1_p1_l2_w('vipno', 'pluno', data, 'UI')\n",
    "    data = features_type1_p1_l2_m('vipno', 'pluno', data, 'UI')\n",
    "    # brand and category\n",
    "    data = features_type1_p1_l2_w('bndno', 'dptno', data, 'BC')\n",
    "    data = features_type1_p1_l2_m('bndno', 'dptno', data, 'BC')\n",
    "    # p2\n",
    "    # group by user\n",
    "    data = features_type1_p2_w('vipno', 'pluno', data, 'U', 'I')\n",
    "    data = features_type1_p2_m('vipno', 'pluno', data, 'U', 'I')\n",
    "    data = features_type1_p2_w('vipno', 'bndno', data, 'U', 'B')\n",
    "    data = features_type1_p2_m('vipno', 'bndno', data, 'U', 'B')\n",
    "    data = features_type1_p2_w('vipno', 'dptno', data, 'U', 'C')\n",
    "    data = features_type1_p2_m('vipno', 'dptno', data, 'U', 'C')\n",
    "    # group by brand \n",
    "    data = features_type1_p2_w('bndno', 'pluno', data, 'B', 'I')\n",
    "    data = features_type1_p2_m('bndno', 'pluno', data, 'B', 'I')\n",
    "    # group by category\n",
    "    data = features_type1_p2_w('dptno', 'pluno', data, 'C', 'I')\n",
    "    data = features_type1_p2_m('dptno', 'pluno', data, 'C', 'I')\n",
    "    # p3\n",
    "    # group by brand\n",
    "    data = features_type1_p2_w('bndno', 'vipno', data, 'B', 'U')\n",
    "    data = features_type1_p2_m('bndno', 'vipno', data, 'B', 'U')\n",
    "    # group by category\n",
    "    data = features_type1_p2_w('dptno', 'vipno', data, 'C', 'U')\n",
    "    data = features_type1_p2_m('dptno', 'vipno', data, 'C', 'U')\n",
    "    # group by item\n",
    "    data = features_type1_p2_w('pluno', 'vipno', data, 'I', 'U')\n",
    "    data = features_type1_p2_m('pluno', 'vipno', data, 'I', 'U')\n",
    "\n",
    "    return data\n",
    "\n",
    "def type2(data):\n",
    "\n",
    "    # p1\n",
    "    feature1 = data.columns[25:]\n",
    "    for feature in feature1:\n",
    "        if feature.count('_m') > 0:\n",
    "            data = features_type2_p1(feature, data)\n",
    "\n",
    "    # p2\n",
    "    data = features_type2_p2('bndno', 'vipno', data, '')\n",
    "    data = features_type2_p2('dptno', 'vipno', data, '')\n",
    "    data = features_type2_p2('pluno', 'vipno', data, '')\n",
    "\n",
    "    # p3\n",
    "    data = features_type2_p2('vipno', 'bndno', data, '')\n",
    "    data = features_type2_p2('vipno', 'dptno', data, '')\n",
    "    data = features_type2_p2('vipno', 'pluno', data, '')\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_date(day):\n",
    "\n",
    "    return datetime.datetime.strptime('2016-'+day,'%Y-%m-%d')\n",
    "\n",
    "def type3(data):\n",
    "\n",
    "    groups = {}\n",
    "\n",
    "    data['date'] = data['day'].apply(get_date)\n",
    "\n",
    "    start_date = datetime.date(2016,1,31)\n",
    "    end_date = datetime.date(2016,7,31)\n",
    "\n",
    "    day = start_date\n",
    "\n",
    "    while day < end_date:\n",
    "\n",
    "        day += datetime.timedelta(days=1)  \n",
    "\n",
    "        group = data[(data['date'] <= day) & (data['date'] > day-datetime.timedelta(days=7))].reset_index(drop=True)\n",
    "\n",
    "        # type1\n",
    "        # group by user\n",
    "        group = features_type1_p1_l1_w('vipno', group, 'U_last7day')\n",
    "        # group by brand\n",
    "        group = features_type1_p1_l1_w('bndno', group, 'B_last7day')\n",
    "        # group by category\n",
    "        group = features_type1_p1_l1_w('dptno', group, 'C_last7day')\n",
    "        # group by item\n",
    "        group = features_type1_p1_l1_w('pluno', group, 'I_last7day')\n",
    "        # user and brand\n",
    "        group = features_type1_p1_l2_w('vipno', 'bndno', group, 'UB_last7day')\n",
    "        # user and category\n",
    "        group = features_type1_p1_l2_w('vipno', 'dptno', group, 'UC_last7day')\n",
    "        # user and item \n",
    "        group = features_type1_p1_l2_w('vipno', 'pluno', group, 'UI_last7day')\n",
    "        # brand and category\n",
    "        group = features_type1_p1_l2_w('bndno', 'dptno', group, 'BC_last7day')\n",
    "        # p2\n",
    "        # group by user\n",
    "        group = features_type1_p2_w('vipno', 'pluno', group, 'U_last7day', 'I_last7day')\n",
    "        group = features_type1_p2_w('vipno', 'bndno', group, 'U_last7day', 'B_last7day')\n",
    "        group = features_type1_p2_w('vipno', 'dptno', group, 'U_last7day', 'C_last7day')\n",
    "        # group by brand \n",
    "        group = features_type1_p2_w('bndno', 'pluno', group, 'B_last7day', 'I_last7day')\n",
    "        # group by category\n",
    "        group = features_type1_p2_w('dptno', 'pluno', group, 'C_last7day', 'I_last7day')\n",
    "        # p3\n",
    "        # group by brand\n",
    "        group = features_type1_p2_w('bndno', 'vipno', group, 'B_last7day', 'U_last7day')\n",
    "        # group by category\n",
    "        group = features_type1_p2_w('dptno', 'vipno', group, 'C_last7day', 'U_last7day')\n",
    "        # group by item\n",
    "        group = features_type1_p2_w('pluno', 'vipno', group, 'I_last7day', 'U_last7day')\n",
    "\n",
    "        # type2\n",
    "        # p2\n",
    "        group = features_type2_p2('bndno', 'vipno', group, '_last7day')\n",
    "        group = features_type2_p2('dptno', 'vipno', group, '_last7day')\n",
    "        group = features_type2_p2('pluno', 'vipno', group, '_last7day')\n",
    "\n",
    "        # p3\n",
    "        group = features_type2_p2('vipno', 'bndno', group, '_last7day')\n",
    "        group = features_type2_p2('vipno', 'dptno', group, '_last7day')\n",
    "        group = features_type2_p2('vipno', 'pluno', group, '_last7day')\n",
    "\n",
    "        groups.setdefault(day, group.set_index(['uid', 'pluno']))\n",
    "\n",
    "        print day\n",
    "\n",
    "    new_data = None\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "\n",
    "        new_row = groups[datetime.date(row['date'].year, row['date'].month, row['date'].day)].loc[row['uid'], row['pluno']].iloc[[0]]\n",
    "        if type(new_data) == type(None):\n",
    "            new_data = new_row\n",
    "        else:\n",
    "            new_data = new_data.append(new_row)\n",
    "\n",
    "    return new_data.reset_index()\n",
    "\n",
    "def type4(data):\n",
    "\n",
    "    # p1\n",
    "    # group by user\n",
    "    data = features_type4_p1_l1('vipno', data, 'U')\n",
    "    # group by brand\n",
    "    data = features_type4_p1_l1('bndno', data, 'B')\n",
    "    # group by category\n",
    "    data = features_type4_p1_l1('dptno', data, 'C')\n",
    "    # group by item\n",
    "    data = features_type4_p1_l1('pluno', data, 'I')\n",
    "    # user and brand\n",
    "    data = features_type4_p1_l2('vipno', 'bndno', data, 'UB')\n",
    "    # user and category\n",
    "    data = features_type4_p1_l2('vipno', 'dptno', data, 'UC')\n",
    "    # user and item \n",
    "    data = features_type4_p1_l2('vipno', 'pluno', data, 'UI')\n",
    "    # brand and category\n",
    "    data = features_type4_p1_l2('bndno', 'dptno', data, 'BC')\n",
    "    # p2\n",
    "    # group by user\n",
    "    data = features_type4_p1_l3('vipno', 'pluno', data, 'U', 'I')\n",
    "    data = features_type4_p1_l3('vipno', 'bndno', data, 'U', 'B')\n",
    "    data = features_type4_p1_l3('vipno', 'dptno', data, 'U', 'C')\n",
    "    # group by brand \n",
    "    data = features_type4_p1_l3('bndno', 'pluno', data, 'B', 'I')\n",
    "    # group by category\n",
    "    data = features_type4_p1_l3('dptno', 'pluno', data, 'C', 'I')\n",
    "    # group by brand\n",
    "    data = features_type4_p1_l3('bndno', 'vipno', data, 'B', 'U')\n",
    "    # group by category\n",
    "    data = features_type4_p1_l3('dptno', 'vipno', data, 'C', 'U')\n",
    "    # group by item\n",
    "    data = features_type4_p1_l3('pluno', 'vipno', data, 'I', 'U')\n",
    "    # p2\n",
    "    ## brand\n",
    "    data = features_type4_p2_t1('bndno', data)\n",
    "    ## category\n",
    "    data = features_type4_p2_t1('dptno', data)\n",
    "    ## item\n",
    "    data = features_type4_p2_t1('pluno', data)\n",
    "    ## user\n",
    "    data = features_type4_p2_t2('bndno', data)\n",
    "    data = features_type4_p2_t2('dptno', data)\n",
    "    data = features_type4_p2_t2('pluno', data)\n",
    "    # p3\n",
    "    data = features_type4_p3('bndno', 'dptno', data)\n",
    "    data = features_type4_p3('dptno', 'bndno', data)\n",
    "    # p4\n",
    "    data = features_type4_p4('bndno', 'dptno', data)\n",
    "    data = features_type4_p4('dptno', 'bndno', data)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    data_set = input()\n",
    "\n",
    "    # TYPE1\n",
    "    features_type1 = type1(data_set)\n",
    "    # TYPE2\n",
    "    features_type2 = type2(features_type1)\n",
    "    # TYPE3\n",
    "    features_type3 = type3(features_type2)\n",
    "    # TYPE4\n",
    "    features_type4 = type4(features_type3)\n",
    "\n",
    "\n",
    "    features_type4.to_csv('type4.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
